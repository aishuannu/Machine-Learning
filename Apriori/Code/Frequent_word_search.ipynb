{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from efficient_apriori import apriori as apriori1\n",
    "import itertools as it\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_kos = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/bag-of-words/vocab.kos.txt\", header = None)\n",
    "#vocab_nips = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/bag-of-words/vocab.nips.txt\", header =  None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docword_enron = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/bag-of-words/docword.kos.txt.gz\", header = None)\n",
    "#docword_enron = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/bag-of-words/docword.nips.txt.gz\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vopcab = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/bag-of-words/vocab.kos.txt\", header = None)\n",
    "docword = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/bag-of-words/docword.kos.txt.gz\", header = None)\n",
    "n = 0.2\n",
    "k = 4\n",
    "\n",
    "data = docword[0:3]\n",
    "data_NNZ = docword[3:]\n",
    "data_NNZ.columns = [\"NNZ\"]\n",
    "#data_enron_NNZ.head()\n",
    "\n",
    "data_NNZ = data_NNZ['NNZ'].str.split(\" \")\n",
    "\n",
    "data_NNZ = pd.DataFrame(list(data_NNZ))\n",
    "data_NNZ.columns = [\"Doc_id\",\"Word_id\",\"Count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "for i in range(0,len(list(vopcab[0]))):\n",
    "    words[i+1] = vopcab[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = data_NNZ.groupby('Doc_id')['Word_id'].apply(list).to_dict()\n",
    "\n",
    "words_in_doc = list(dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oht_ary = te.fit(words_in_doc).transform(words_in_doc, sparse=True)\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(words_in_doc).transform(words_in_doc)\n",
    "sparse_words_matrix = pd.SparseDataFrame(te_ary, columns=te.columns_, default_fill_value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(sparse_words_matrix, min_support = n, max_len=k ,use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "#frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.clock()\n",
    "time_apriori = (end_time-start_time)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09255336715000002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: itemsets, dtype: float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets[frequent_itemsets.length == k].itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient aproiri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`min_support` must be a number between 0 and 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-50fbb6788f30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mitemsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapriori1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_in_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_support\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmin_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mG:\\Software Instalation\\Anaconda\\lib\\site-packages\\efficient_apriori\\apriori.py\u001b[0m in \u001b[0;36mapriori\u001b[1;34m(transactions, min_support, min_confidence, max_length, verbosity)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m     52\u001b[0m     itemsets, num_trans = itemsets_from_transactions(transactions, min_support, \n\u001b[1;32m---> 53\u001b[1;33m                                                      max_length, verbosity)\n\u001b[0m\u001b[0;32m     54\u001b[0m     rules = generate_rules_apriori(itemsets, min_confidence, num_trans, \n\u001b[0;32m     55\u001b[0m                                    verbosity)\n",
      "\u001b[1;32mG:\\Software Instalation\\Anaconda\\lib\\site-packages\\efficient_apriori\\itemsets.py\u001b[0m in \u001b[0;36mitemsets_from_transactions\u001b[1;34m(transactions, min_support, max_length, verbosity)\u001b[0m\n\u001b[0;32m    213\u001b[0m     if not (isinstance(min_support, numbers.Number) and\n\u001b[0;32m    214\u001b[0m             (0 <= min_support <= 1)):\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`min_support` must be a number between 0 and 1.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;31m# Keep a dictionary stating whether to consider the row, this will allow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `min_support` must be a number between 0 and 1."
     ]
    }
   ],
   "source": [
    "itemsets, rules = apriori1(words_in_doc, min_support=n,  min_confidence=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.clock()\n",
    "time_apriori = (end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    frequent_word_id = list(itemsets[k].keys())\n",
    "except KeyError:\n",
    "    print(\"No such values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frequent_word = []\n",
    "for i in range(len(frequent_word_id)):\n",
    "    temp_word = []\n",
    "    for j in range(k):\n",
    "        temp_word.append(words[int(frequent_word_id[i][j])])\n",
    "    frequent_word.append(temp_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_word_with_len = pd.DataFrame(frequent_word, columns = list(\"word \"+str(i+1) for i in range(k))) \n",
    "\n",
    "frequent_word_with_len[\"Freq\"] = list(itemsets[k].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
