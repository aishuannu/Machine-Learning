{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Aritra Banerjee\n",
    "2. Aishwarya R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from bs4 import BeautifulSoup,SoupStrainer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "f = open(\"output_of_naive_bayes.txt\",'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Data (Creating Test Train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_parsing = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "train_category = []\n",
    "test_category = []\n",
    "lis = [\"0\" + str(i) for i in range(10)] + list(range(10,22))\n",
    "for file_name in lis:\n",
    "    f = open('data/reut2-0'+str(file_name)+'.sgm', 'r')\n",
    "    data= f.read()\n",
    "    soup = BeautifulSoup(data)\n",
    "    contents_train = soup.find_all('reuters', lewissplit=\"TRAIN\") or soup.find_all('reuters', lewissplit=\"NOT-USED\") \n",
    "    #contents_train = soup.find_all('reuters', cgisplit=\"TRAINING-SET\")\n",
    "    \n",
    "    for doc_train in range(0,len(contents_train)):\n",
    "        try:\n",
    "            temp_train = []\n",
    "            for node in contents_train[doc_train].topics.find_all('d'):\n",
    "                temp_train.append(''.join(node.findAll(text=True)))\n",
    "            if temp_train[0] != '':\n",
    "                if contents_train[doc_train].find('body') != None:\n",
    "                    train.append(contents_train[doc_train].title.text + contents_train[doc_train].body.string)\n",
    "                    train_category.append(temp_train)\n",
    "                elif contents_train[doc_train].find('text', type = 'UNPROC') != None:\n",
    "                    train.append(contents_train[doc_train].find('text', type = 'UNPROC').text)\n",
    "                    train_category.append(temp_train)\n",
    "                elif contents_train[doc_train].find('text', type = 'BRIEF') != None:\n",
    "                    train.append(contents_train[doc_train].find('text', type = 'BRIEF').title.text)\n",
    "                    train_category.append(temp_train)\n",
    "        except:\n",
    "            continue\n",
    "         \n",
    "         \n",
    "    contents_test = soup.find_all('reuters', lewissplit=\"TEST\")  \n",
    "    #contents_test = soup.find_all('reuters', cgisplit=\"PUBLISHED-TESTSET\")\n",
    "    for doc_test in range(0,len(contents_test)):\n",
    "        try:\n",
    "            temp_test = []\n",
    "            for node in contents_test[doc_test].topics.find_all('d'):\n",
    "                temp_test.append(''.join(node.findAll(text=True)))\n",
    "            if temp_test[0] != '':\n",
    "                if contents_test[doc_test].find('body') != None:\n",
    "                    test.append(contents_test[doc_test].title.text + contents_test[doc_test].body.string)\n",
    "                    test_category.append(temp_test)\n",
    "                elif contents_test[doc_test].find('text', type = 'UNPROC') != None:\n",
    "                    test.append(contents_test[doc_test].find('text', type = 'UNPROC').text)\n",
    "                    test_category.append(temp_test)\n",
    "                elif contents_test[doc_test].find('text', type = 'BRIEF') != None:\n",
    "                    test.append(contents_test[doc_test].find('text', type = 'BRIEF').title.text)\n",
    "                    test_category.append(temp_test)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_parsing = time.clock()\n",
    "time_parsing = (end_time_parsing-start_time_parsing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.DataFrame(train)\n",
    "# train_category_data = pd.DataFrame(train_category)\n",
    "# test_data = pd.DataFrame(test)\n",
    "# test_category_data = pd.DataFrame(test_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_cat = []\n",
    "for i in train_category:\n",
    "    all_train_cat = all_train_cat + i\n",
    "    \n",
    "all_test_cat = []\n",
    "for i in test_category:\n",
    "    all_test_cat = all_test_cat + i\n",
    "\n",
    "not_in_train = set(all_test_cat).difference(set(all_train_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for i in range(len(test_category)):\n",
    "    if not_in_train.intersection(set(test_category[i])) != set():\n",
    "        idx.append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in idx:\n",
    "    train.append(test[i-count])\n",
    "    train_category.append(test_category[i-count])\n",
    "    test.pop(i-count)\n",
    "    test_category.pop(i-count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7827</td>\n",
       "      <td>7827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7827</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>PHILIPPINE COCONUT INDUSTRY WORRIED BY EC TAXP...</td>\n",
       "      <td>[earn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body   label\n",
       "count                                                7827    7827\n",
       "unique                                               7827     492\n",
       "top     PHILIPPINE COCONUT INDUSTRY WORRIED BY EC TAXP...  [earn]\n",
       "freq                                                    1    2837"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = zip(train,train_category)\n",
    "data = pd.DataFrame(data,columns=(\"body\",\"label\"))\n",
    "\n",
    "data.drop_duplicates(subset=\"body\",inplace=True)\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(data.body)\n",
    "train_category = list(data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid = re.compile(r\"[\\t\\n\\/\\x03\\,\\.\\\"\\']+\") \n",
    "def map_all(doc):\n",
    "    return(invalid.sub(' ', doc))\n",
    "\n",
    "invalid_1 = re.compile(r'\\b[\\d.]*[\\d]+\\b')\n",
    "def map_all_2(doc):\n",
    "    return(invalid_1.sub(' ', doc))\n",
    "\n",
    "train = map(map_all,train)\n",
    "train = map(map_all_2,train)\n",
    "test = map(map_all,test)\n",
    "test = map(map_all_2,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the data for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " start_time_model = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "train_array = te.fit(train_category).transform(train_category)\n",
    "train_matrix = pd.SparseDataFrame(train_array, columns=te.columns_, default_fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = te.fit(train_category).transform(test_category)\n",
    "test_matrix = pd.SparseDataFrame(test_array, columns=te.columns_, default_fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorised_train_documents = vectorizer.fit_transform(train)\n",
    "vectorised_test_documents = vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None, alpha=0.01))\n",
    "classifier.fit(vectorised_train_documents, train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(vectorised_test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_model = time.clock()\n",
    "time_model = (end_time_model - start_time_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(test_array, predictions,average='micro')\n",
    "#recall = recall_score(test_array, predictions,average='micro')\n",
    "f1 = f1_score(test_array, predictions, average='micro')\n",
    "\n",
    "accuracy = accuracy_score(predictions, test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping prediction to the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_category = []\n",
    "for j in predictions:\n",
    "    res = [i for i, val in enumerate(j) if val]\n",
    "    temp = []\n",
    "    for k in res:\n",
    "        temp.append(test_matrix.columns[k])\n",
    "    predicted_category.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = zip(test_category, predicted_category)\n",
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.write(\"Output of Naive Bayes::::  \")\n",
    "f.write(\"\\n\")\n",
    "f.write(\"\\n\")\n",
    "\n",
    "len_train = str(len(train))\n",
    "len_test = str(len(test))\n",
    "f.write(\"Length of the training data is::::  \")\n",
    "f.write(len_train)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"Length of the test data is::::  \")\n",
    "f.write(len_test)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"\\n\")\n",
    "\n",
    "\n",
    "f.write(\"Micro-average quality numbers::::  \")\n",
    "f.write(\"Precision::::  \")\n",
    "f.write(str(precision))\n",
    "f.write(\"\\n\")\n",
    "f.write(\"F1 score::::  \")\n",
    "f.write(str(f1))\n",
    "f.write(\"\\n\")        \n",
    "f.write(\"Accuracy-score::::  \")\n",
    "f.write(str(accuracy))\n",
    "f.write(\"\\n\")\n",
    "f.write(\"\\n\")\n",
    "    \n",
    "f.write(\"\\n\")   \n",
    "f.write(\"Time taken is::::  \")\n",
    "f.write(str(time_parsing))\n",
    "f.write(\"\\n\")        \n",
    "f.write(\"Time taken is::::  \")\n",
    "f.write(str(time_model))\n",
    "f.write(\"\\n\")\n",
    "\n",
    "f.write(\"The output is::::  \")\n",
    "f.write(\"\\n\")\n",
    "f.write(str(output))\n",
    "f.write(\"\\n\")\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
